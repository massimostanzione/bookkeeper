<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml" lang="it"><head><meta http-equiv="Content-Type" content="text/html;charset=UTF-8"/><link rel="stylesheet" href="../jacoco-resources/report.css" type="text/css"/><link rel="shortcut icon" href="../jacoco-resources/report.gif" type="image/gif"/><title>EntryLogCompactor.java</title><link rel="stylesheet" href="../jacoco-resources/prettify.css" type="text/css"/><script type="text/javascript" src="../jacoco-resources/prettify.js"></script></head><body onload="window['PR_TAB_WIDTH']=4;prettyPrint()"><div class="breadcrumb" id="breadcrumb"><span class="info"><a href="../jacoco-sessions.html" class="el_session">Sessions</a></span><a href="../index.html" class="el_report">Apache BookKeeper :: Server</a> &gt; <a href="index.source.html" class="el_package">org.apache.bookkeeper.bookie</a> &gt; <span class="el_source">EntryLogCompactor.java</span></div><h1>EntryLogCompactor.java</h1><pre class="source lang-java linenums">/**
 *
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * &quot;License&quot;); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing,
 * software distributed under the License is distributed on an
 * &quot;AS IS&quot; BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 * KIND, either express or implied.  See the License for the
 * specific language governing permissions and limitations
 * under the License.
 *
 */

package org.apache.bookkeeper.bookie;

import java.io.IOException;
import java.nio.ByteBuffer;
import java.util.ArrayList;
import java.util.List;

import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

/**
 * This is the basic entry log compactor to compact entry logs.
 * The compaction is done by scanning the old entry log file, copy the active ledgers to the
 * current entry logger and remove the old entry log when the scan is over.
 */
public class EntryLogCompactor extends AbstractLogCompactor {
<span class="fc" id="L38">    private static final Logger LOG = LoggerFactory.getLogger(EntryLogCompactor.class);</span>

<span class="fc" id="L40">    final CompactionScannerFactory scannerFactory = new CompactionScannerFactory();</span>
    final EntryLogger entryLogger;
    final CompactableLedgerStorage ledgerStorage;
    private final int maxOutstandingRequests;

    public EntryLogCompactor(GarbageCollectorThread gcThread) {
<span class="fc" id="L46">        super(gcThread);</span>
<span class="fc" id="L47">        this.maxOutstandingRequests = conf.getCompactionMaxOutstandingRequests();</span>
<span class="fc" id="L48">        this.entryLogger = gcThread.getEntryLogger();</span>
<span class="fc" id="L49">        this.ledgerStorage = gcThread.getLedgerStorage();</span>
<span class="fc" id="L50">    }</span>

    @Override
    public boolean compact(EntryLogMetadata entryLogMeta) {
        try {
<span class="nc" id="L55">            entryLogger.scanEntryLog(entryLogMeta.getEntryLogId(),</span>
<span class="nc" id="L56">                scannerFactory.newScanner(entryLogMeta));</span>
<span class="nc" id="L57">            scannerFactory.flush();</span>
<span class="nc" id="L58">            LOG.info(&quot;Removing entry log {} after compaction&quot;, entryLogMeta.getEntryLogId());</span>
<span class="nc" id="L59">            gcThread.removeEntryLog(entryLogMeta.getEntryLogId());</span>
<span class="nc" id="L60">        } catch (LedgerDirsManager.NoWritableLedgerDirException nwlde) {</span>
<span class="nc" id="L61">            LOG.warn(&quot;No writable ledger directory available, aborting compaction&quot;, nwlde);</span>
<span class="nc" id="L62">            return false;</span>
<span class="nc" id="L63">        } catch (IOException ioe) {</span>
            // if compact entry log throws IOException, we don't want to remove that
            // entry log. however, if some entries from that log have been re-added
            // to the entry log, and the offset updated, it's ok to flush that
<span class="nc" id="L67">            LOG.error(&quot;Error compacting entry log. Log won't be deleted&quot;, ioe);</span>
<span class="nc" id="L68">            return false;</span>
<span class="nc" id="L69">        }</span>
<span class="nc" id="L70">        return true;</span>
    }

    /**
     * A scanner wrapper to check whether a ledger is alive in an entry log file.
     */
<span class="fc" id="L76">    class CompactionScannerFactory {</span>
<span class="fc" id="L77">        List&lt;EntryLocation&gt; offsets = new ArrayList&lt;EntryLocation&gt;();</span>

        EntryLogger.EntryLogScanner newScanner(final EntryLogMetadata meta) {

<span class="nc" id="L81">            return new EntryLogger.EntryLogScanner() {</span>
                @Override
                public boolean accept(long ledgerId) {
<span class="nc" id="L84">                    return meta.containsLedger(ledgerId);</span>
                }

                @Override
                public void process(final long ledgerId, long offset, ByteBuffer entry) throws IOException {
<span class="nc" id="L89">                    throttler.acquire(entry.remaining());</span>

<span class="nc bnc" id="L91" title="All 2 branches missed.">                    if (offsets.size() &gt; maxOutstandingRequests) {</span>
<span class="nc" id="L92">                        flush();</span>
                    }
<span class="nc" id="L94">                    entry.getLong(); // discard ledger id, we already have it</span>
<span class="nc" id="L95">                    long entryId = entry.getLong();</span>
<span class="nc" id="L96">                    entry.rewind();</span>

<span class="nc" id="L98">                    long newoffset = entryLogger.addEntry(ledgerId, entry);</span>
<span class="nc" id="L99">                    offsets.add(new EntryLocation(ledgerId, entryId, newoffset));</span>

<span class="nc" id="L101">                }</span>
            };
        }

        void flush() throws IOException {
<span class="nc bnc" id="L106" title="All 2 branches missed.">            if (offsets.isEmpty()) {</span>
<span class="nc bnc" id="L107" title="All 2 branches missed.">                if (LOG.isDebugEnabled()) {</span>
<span class="nc" id="L108">                    LOG.debug(&quot;Skipping entry log flushing, as there are no offset!&quot;);</span>
                }
<span class="nc" id="L110">                return;</span>
            }

            // Before updating the index, we want to wait until all the compacted entries are flushed into the
            // entryLog
            try {
<span class="nc" id="L116">                entryLogger.flush();</span>
<span class="nc" id="L117">                ledgerStorage.updateEntriesLocations(offsets);</span>
            } finally {
<span class="nc" id="L119">                offsets.clear();</span>
            }
<span class="nc" id="L121">        }</span>
    }
}
</pre><div class="footer"><span class="right">Created with <a href="http://www.jacoco.org/jacoco">JaCoCo</a> 0.8.2.201808211720</span></div></body></html>